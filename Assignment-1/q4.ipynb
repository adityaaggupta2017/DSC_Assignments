{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from scipy.stats import poisson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the \"Hurricane\" csv from the excel file mentioned in the question . Now we can apply changes as asked in the questions . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PART - A\n",
    "\n",
    "In this part of the question we need to write program for t-test for correlation coefficient with a 1% level of significance between \"“Max. sustained winds(mph)” and “Minimum pressure(mbar)”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Assignment-1 - Hurricane.csv')\n",
    "\n",
    "wind_speed = dataset['Max. sustained winds(mph)'] ;  \n",
    "\n",
    "min_pressure = dataset['Minimum pressure(mbar)'] ; \n",
    "\n",
    "wind_speed = np.array(wind_speed) ; \n",
    "min_pressure = np.array(min_pressure) ; \n",
    "# print(wind_speed.shape) ; \n",
    "# print(wind_speed) ; \n",
    "# print(min_pressure.shape) ;  \n",
    "# print(min_pressure) ;  \n",
    "\n",
    "\n",
    "# Now we have got the column values in the np arrays . Now we can proceed with the t_test ; \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using t_test to conduct t-test for correlation coefficient between “Max. sustained winds(mph)” and “Minimum pressure(mbar)” with 1% level of significance . Thus we formulate the hypothesis first : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Hypothesis (H₀)\n",
    "There is no significant correlation between the two variables.\n",
    "\n",
    "- H₀: ρ = 0\n",
    "\n",
    "### Alternative Hypothesis (H₁)\n",
    "There is a significant correlation between the two variables (two-tailed test).\n",
    "\n",
    "- H₁: ρ ≠ 0\n",
    "\n",
    "Let us first calculate the value of r (Pearson Correlation Coefficient) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of r is : -0.48359549563566406\n",
      "The degree of freedom is: 99\n",
      "Value of t comes out to be: -5.497270157344813\n"
     ]
    }
   ],
   "source": [
    "# let r be the correlation coefficient . \n",
    "\n",
    "def calculate_mean(data) : \n",
    "  if (len(data) == 0):\n",
    "    return None ; \n",
    "  \n",
    "  return sum(data) / len(data) ;  \n",
    "\n",
    "\n",
    "def calculate_num(wind_speed , min_pressure): \n",
    "  mean_wind_speed = calculate_mean(wind_speed) ; \n",
    "  \n",
    "  mean_min_pressure = calculate_mean(min_pressure) ; \n",
    "  \n",
    "  ans = 0 ; \n",
    "  \n",
    "  for i in range(len(wind_speed)): \n",
    "    \n",
    "    first_term = (wind_speed[i] - mean_wind_speed) ; \n",
    "    second_term = (min_pressure[i] -mean_min_pressure) ; \n",
    "    \n",
    "    ans += first_term * second_term ; \n",
    "  \n",
    "  return ans ; \n",
    "\n",
    "def calculate_den(wind_speed , min_pressure):\n",
    "  mean_wind_speed = calculate_mean(wind_speed) ; \n",
    "  \n",
    "  mean_min_pressure = calculate_mean(min_pressure) ; \n",
    "  \n",
    "  ans = 0 ; \n",
    "  \n",
    "  first_term = 0 ; \n",
    "  second_term = 0 ; \n",
    "  \n",
    "  for i in range(len(wind_speed)):\n",
    "    first_term += (wind_speed[i] - mean_wind_speed) ** 2 ; \n",
    "  \n",
    "  for i in range(len(min_pressure)):\n",
    "    second_term += (min_pressure[i] - mean_min_pressure) ** 2 ; \n",
    "  \n",
    "  \n",
    "  ans = first_term * second_term ; \n",
    "  \n",
    "  ans = ans ** (1/2) ; \n",
    "  \n",
    "  return ans ; \n",
    "\n",
    "numerator = calculate_num(wind_speed, min_pressure)\n",
    "denominator = calculate_den(wind_speed, min_pressure)\n",
    "\n",
    "if denominator != 0:  # To avoid division by zero\n",
    "    r = numerator / denominator\n",
    "else:\n",
    "    r = None\n",
    "\n",
    "\n",
    "print(\"The value of r is : \" + str(r)) \n",
    "\n",
    "\n",
    "den_term = math.sqrt(1 - r * r) ; \n",
    "\n",
    "n = len(wind_speed) ; \n",
    "\n",
    "t = (r / den_term) * (math.sqrt(n - 2)) ; \n",
    "\n",
    "degree_of_freedom = (n - 2) ; \n",
    "\n",
    "print(\"The degree of freedom is: \" + str(degree_of_freedom)) ; \n",
    "print(\"Value of t comes out to be: \" + str(t)) ;  # we get the t-value from here . \n",
    "\n",
    "# Thus from the t-table shared to us , we can see that the value of alpha = 0.01 .(as the significance is 1% and the test is two tailed) . The value for n = 90 , cutoff = 2.632 and for n = 100 , cutoff = 2.626 . \n",
    "\n",
    "# Thus we know -5.49 < -2.632 , Thus we will reject the null hypothesis . \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus from the t-table shared to us , we can see that the value of alpha = 0.01 .(as the significance is 1% and the test is two tailed) . The value for n = 90 , cutoff = 2.632 and for n = 100 , cutoff = 2.626 . \n",
    "\n",
    "Thus we know -5.49 < -2.632 , Thus we will reject the null hypothesis . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we clean the data manually for such columns where there are garbage values in the month column . This way we make the dataset consistent and ready for use . I will be using one hot encoding for the categorical columns . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add additional columns for the speed and the months as we are using one hot encoding thus changing them to numerical values of 0 and 1 . After this we will drop the categorical columns . We are also saving this new dataset as \"Cleaned_hurricane.csv\" . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cleaned = pd.read_csv('Assignment-1 - Hurricane.csv')\n",
    "\n",
    "wind_speed = dataset_cleaned['Max. sustained winds(mph)'] ; \n",
    "months = dataset_cleaned['Month']\n",
    "# print(wind_speed.unique()) # they are only 5 in number \n",
    "\n",
    "# thus speed is also a categorical column and so is the months \n",
    "\n",
    "# thus first change the columns into one hot encodings \n",
    " \n",
    "unique_wind_speed = wind_speed.unique() ; \n",
    "\n",
    "unique_months = set()\n",
    "\n",
    "for entry in months:\n",
    "    unique_months.update(entry.split(\", \"))\n",
    "  \n",
    "for speed in unique_wind_speed:\n",
    "    dataset_cleaned[f'Wind_{speed}mph'] = wind_speed.apply(lambda x: 1 if x == speed else 0)\n",
    "    \n",
    "\n",
    "for month in unique_months:\n",
    "    dataset_cleaned[month] = months.apply(lambda x: 1 if month in x.split(\", \") else 0)\n",
    "  \n",
    "dataset_cleaned = dataset_cleaned.drop(['Max. sustained winds(mph)', 'Month'], axis=1)\n",
    "\n",
    "# print(dataset_cleaned)\n",
    "\n",
    "dataset_cleaned.to_csv(\"Cleaned_hurricane.csv\") \n",
    "\n",
    "\n",
    "# thus we successfully used one hot encodint in this dataset . Now we can move on forward . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use chi squared testing for independence as both the columns are categorical columns . Thus we make the hypothesis as follows : \n",
    "## Hypotheses for Chi-Squared Test\n",
    "\n",
    "### Null Hypothesis (H0)\n",
    "The null hypothesis states that there is no association between the “Max. sustained winds(mph)” and the Months. In other words, the two variables are independent.\n",
    "\n",
    "**H₀**: The “Max. sustained winds(mph)” is independent of the Months.\n",
    "\n",
    "### Alternative Hypothesis (H1)\n",
    "The alternative hypothesis states that there is an association between “Max. sustained winds(mph)” and the Months . This means that the two variables are dependent.\n",
    "\n",
    "**H₁**: The“Max. sustained winds(mph)” is dependent on the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind Speed by Month Table:\n",
      "             August  November  July  October  September\n",
      "Wind_150mph       8         0     0        5         11\n",
      "Wind_140mph       9         1     1       10         18\n",
      "Wind_155mph       4         1     0        2          6\n",
      "Wind_130mph       7         0     0        5         16\n",
      "Wind_145mph       7         1     0        8         17\n",
      "\n",
      "Chi-Squared Value: 7.971634778620072\n",
      "Degrees of Freedom: 16\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(dataset_cleaned) ; \n",
    "\n",
    "wind_speed_cols = dataframe.filter(like='Wind_')\n",
    "month_cols = ['August', 'November', 'July', 'October', 'September']\n",
    "\n",
    "wind_speed_by_month = pd.DataFrame(0, index=wind_speed_cols.columns, columns=month_cols)\n",
    "\n",
    "\n",
    "for i, row in dataframe.iterrows():\n",
    "    \n",
    "    for wind_col in wind_speed_cols.columns:\n",
    "        if row[wind_col] == 1:  \n",
    "            for month in month_cols:\n",
    "                if row[month] == 1:  \n",
    "                    wind_speed_by_month.loc[wind_col, month] += 1\n",
    "\n",
    "\n",
    "print(\"Wind Speed by Month Table:\")\n",
    "print(wind_speed_by_month)\n",
    "\n",
    "\n",
    "observed_data = wind_speed_by_month.values\n",
    "row_sums = observed_data.sum(axis=1)\n",
    "column_sums = observed_data.sum(axis=0)\n",
    "total_sum = observed_data.sum()\n",
    "\n",
    "expected = np.outer(row_sums, column_sums) / total_sum\n",
    "\n",
    "chi_squared_val = ((observed_data - expected) ** 2 / expected).sum()\n",
    "\n",
    "degree_of_freedom = (observed_data.shape[0] - 1) * (observed_data.shape[1] - 1)\n",
    "\n",
    "print(\"\\nChi-Squared Value:\", chi_squared_val)\n",
    "print(\"Degrees of Freedom:\", degree_of_freedom)\n",
    "\n",
    "# now the chi squared value for degree of freedom 12 and significance 5 % (as it is always a one sided tailed test) is : 21.026 . Thus , 7.971634778620072 < 21.026 so we will not reject the null hypothesis . \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we get that 7.97 < 21.02 , thus we will not reject the null hypothesis . Thus , we conclude that “Max. sustained winds(mph)” is independent of month in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we need to test with significance of 10% that if “Max. sustained winds(mph)” follows a Poisson distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses for Chi-Squared Goodness of Fit Test\n",
    "\n",
    "**Null Hypothesis (\\(H_0\\))**: The data on \"Max. sustained winds (mph)\" follows a Poisson distribution with the estimated mean \\( \\lambda \\).\n",
    "\n",
    "**Alternative Hypothesis (\\(H_1\\)**: The data on \"Max. sustained winds (mph)\" does not follow a Poisson distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets solve for the same using chi-square test for goodness of fit . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Normalizing the Expected Frequencies to make sum of Expected Frequencies same as Observed Frequencies . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of chi_squared_value is: 631.9284580912764\n",
      "The value of degree of freedom is: 3\n",
      "130    23\n",
      "140    28\n",
      "145    24\n",
      "150    18\n",
      "155     8\n",
      "Name: count, dtype: int64\n",
      "{130: 2.1165926889411204, 140: 3.3610008729380514, 145: 3.232352525315237, 150: 2.6177813492202806, 155: 1.7955316595831554}\n"
     ]
    }
   ],
   "source": [
    "wind_speed_data = dataset['Max. sustained winds(mph)'] ; \n",
    "\n",
    "wind_speed_data = np.array(wind_speed_data) ; \n",
    "\n",
    "# we will first calculate the freq of the wind_speed_data , this is the observed frequencies ; \n",
    "\n",
    "observed_frequencies = pd.Series(wind_speed_data).value_counts().sort_index() ; \n",
    "\n",
    "# now in the poisson distribution we will need to use the lambda value \n",
    "\n",
    "lambda_val = calculate_mean(wind_speed_data) ; \n",
    "\n",
    "total_count = len(wind_speed_data) ; \n",
    "\n",
    "# now we need to compute the expected frequencies (with we are considering as poisson distribution as said in the question) . \n",
    "\n",
    "def poisson_pmf(k, lambda_val):\n",
    "\n",
    "    return poisson.pmf(k, lambda_val)\n",
    "\n",
    "# We are making dictionary to store the expected frequencies \n",
    "\n",
    "expected_frequencies = {} ; \n",
    "\n",
    "for k in observed_frequencies.index: \n",
    "  expected_probablity = poisson_pmf(k , lambda_val) ; \n",
    "  \n",
    "  expected_frequencies[k] = expected_probablity * total_count ; \n",
    "\n",
    "\n",
    "  # print(f\"Wind Speed: {k}, Poisson Probability: {expected_probablity}, Expected Frequency: {expected_frequencies[k]}\")\n",
    "\n",
    "combined_vals = pd.DataFrame({'Observed' : observed_frequencies , 'Expected' : expected_frequencies}) \n",
    "\n",
    "\n",
    "chi_squared_val = ((combined_vals['Observed'] - combined_vals['Expected']) ** 2 / (combined_vals['Expected'])).sum() ; # this is formulae mentioned in the slides \n",
    "\n",
    "m = 1 ; \n",
    "\n",
    "degree_of_freedom = len(observed_frequencies) - 1 - m\n",
    "\n",
    "print(\"The value of chi_squared_value is: \" + str(chi_squared_val))\n",
    "\n",
    "print(\"The value of degree of freedom is: \" + str(degree_of_freedom)) ; \n",
    "\n",
    "# the value of chi-square for degree of freedom = 3 and significance = 0.1 (10 % ) is 6.251 . Now we see 631.92 > 6.251 . Thus we reject the null hypothesis . Thus we conclude that  The data on \"Max. sustained winds (mph)\" does not follow a Poisson distribution.\n",
    "\n",
    "print(observed_frequencies) ; \n",
    "print(expected_frequencies) ; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we reject the null hypothesis . Thus we conclude that  The data on \"Max. sustained winds (mph)\" does not follow a Poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the Expected Frequencies to make sum of Expected Frequencies same as Observed Frequencies . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of chi_squared_value is: 5.649893997595143\n",
      "The value of degree of freedom is: 3\n",
      "130    23\n",
      "140    28\n",
      "145    24\n",
      "150    18\n",
      "155     8\n",
      "Name: count, dtype: int64\n",
      "{130: 2.1165926889411204, 140: 3.3610008729380514, 145: 3.232352525315237, 150: 2.6177813492202806, 155: 1.7955316595831554}\n"
     ]
    }
   ],
   "source": [
    "wind_speed_data = dataset['Max. sustained winds(mph)'] ; \n",
    "\n",
    "wind_speed_data = np.array(wind_speed_data) ; \n",
    "\n",
    "# we will first calculate the freq of the wind_speed_data , this is the observed frequencies ; \n",
    "\n",
    "observed_frequencies = pd.Series(wind_speed_data).value_counts().sort_index() ; \n",
    "\n",
    "# now in the poisson distribution we will need to use the lambda value \n",
    "\n",
    "lambda_val = calculate_mean(wind_speed_data) ; \n",
    "\n",
    "total_count = len(wind_speed_data) ; \n",
    "\n",
    "# now we need to compute the expected frequencies (with we are considering as poisson distribution as said in the question) . \n",
    "\n",
    "def poisson_pmf(k, lambda_val):\n",
    "\n",
    "    return poisson.pmf(k, lambda_val)\n",
    "\n",
    "# We are making dictionary to store the expected frequencies \n",
    "\n",
    "expected_frequencies = {} ; \n",
    "\n",
    "for k in observed_frequencies.index: \n",
    "  expected_probablity = poisson_pmf(k , lambda_val) ; \n",
    "  \n",
    "  expected_frequencies[k] = expected_probablity * total_count ; \n",
    "\n",
    "\n",
    "\n",
    "  # print(f\"Wind Speed: {k}, Poisson Probability: {expected_probablity}, Expected Frequency: {expected_frequencies[k]}\")\n",
    "\n",
    "total_observed = observed_frequencies.sum()\n",
    "total_expected = sum(expected_frequencies.values())\n",
    "\n",
    "if total_expected > 0:\n",
    "    normalized_expected_frequencies = {k: (v / total_expected) * total_observed for k, v in expected_frequencies.items()}\n",
    "else:\n",
    "    normalized_expected_frequencies = expected_frequencies  # If no expected frequencies, keep original\n",
    "\n",
    "\n",
    "\n",
    "combined_vals = pd.DataFrame({'Observed' : observed_frequencies , 'Expected' : normalized_expected_frequencies}) \n",
    "\n",
    "\n",
    "chi_squared_val = ((combined_vals['Observed'] - combined_vals['Expected']) ** 2 / (combined_vals['Expected'])).sum() ; # this is formulae mentioned in the slides \n",
    "\n",
    "m = 1 ; \n",
    "\n",
    "degree_of_freedom = len(observed_frequencies) - 1 - m\n",
    "\n",
    "print(\"The value of chi_squared_value is: \" + str(chi_squared_val))\n",
    "\n",
    "print(\"The value of degree of freedom is: \" + str(degree_of_freedom)) ; \n",
    "\n",
    "# the value of chi-square for degree of freedom = 3 and significance = 0.1 (10 % ) is 6.251 . Now we see 631.92 > 6.251 . Thus we reject the null hypothesis . Thus we conclude that  The data on \"Max. sustained winds (mph)\" does not follow a Poisson distribution.\n",
    "\n",
    "print(observed_frequencies) ; \n",
    "print(expected_frequencies) ; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case 5.64 < 6.251 . Thus we accept the null hypothesis in this case . This is the difference in the two cases i.e without normalizing and with normalizing . "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
